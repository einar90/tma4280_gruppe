% -*- root: ../ex6.tex -*-

\subsection{Runtime} % (fold)

\label{sub:runtime}
Here is a simplified overview of our solvers expected asymptotic runtimes in the different parts of it, and a simplified model for looking at network latency is presented.

\subsubsection{Computational asymptotic runtimes} % (fold)
\label{ssub:asymptotic_runtimes}

\begin{itemize}

	\item \texttt{transpose((a,b))} has an asymptotic runtime of $O(N^2)$. Each element in the matrix \textbf{B}has to be copied into a new matrix \textbf{A}. This is done on the root prosess every time.
	
	\item Both \texttt{fst} and \texttt{fstinv} have an asymptotic runtime of $O(N\log(n))$. As each processors has a part of the whole matrix \textbf{B} this is going to take at most $O(partlens * N\log(n))$ every time these methods are used for every prosess except the root prosess. 
	
	\item Finding $\tilde{x}$ by using eigenvalues is done in $O(N^2)$. This is done in the root prosess every time. 

\end{itemize}

% For a full run..
When we use the solver to run on a given dataset it does 2x \texttt{fst}, 2x \texttt{fstinv}, 2x \texttt{transpose} and solves $\tilde{x}$ once. If we run the solver with a small amount of prosesses the we would expect to see a bottleneck in the \texttt{fst} and \texttt{fstinv} functions. If we have a decent amount of prosesses and a sufficiently large $N$, we would expect to see most time used in the transpose of the matrix and calculations of $+tilde{x}$ as there is one prosess doing all the work here. 





% subsubsection asymptotic_runtimes (end)

\subsubsection{Network latency} % (fold)
\label{ssub:network_latency}

Here we choose to use a simple linear network model where the time to send $b$ bytes is modelled as:
\begin{center}
	\begin{equation}
		T^{comm}(b) = \kappa + \gamma N^2
	\end{equation}
	where $\kappa$ is the network latency and $\gamma$ is the inverse network bandwith.
\end{center}

In our solver the root prosess has to send $N^2$ bytes and recieve $N^2$ bytes between every transpose operation. The whole matrix has to be distributed across the network no matter how we set up the problem, but this could be done more efficiently by making sure every prosess is responsible for distributing $N^2/P$ bytes each.

% subsubsection network_latency (end)


% subsection runtime (end)